defaults:
  - model: lgmamba_lightfsde
  - writer: wandb
  - metrics: brats23_seg
  - datasets: brats23_cached_notest
  - dataloader: brats23
  - transforms: brats23_cached
  - _self_

optimizer:
  _target_: torch.optim.AdamW
  lr: 1e-4
  weight_decay: 1e-5

lr_scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: ${trainer.n_epochs}

loss_function:
  _target_: src.loss.DiceFocalSegLoss
  dice_weight: 1.0
  focal_weight: 1.0
  gamma: 2.0
  alpha: null

writer:
  mode: online
  run_name: lgm_aug_bs6_ep300_lr1e4
  loss_names: ["loss", "loss_dice", "loss_focal", "loss_ds"]

dataloader:
  batch_size: 6
  eval_batch_size: 1
  num_workers: 8
  persistent_workers: true
  prefetch_factor: 2
  pin_memory: true

datasets:
  train:
    cache_dir: "${oc.env:CACHE_DIR,/cloud/cloud-ssd1/cached}"
    cache_in_memory: false
    use_mmap: true
    usage_ratio: 1.0
  val:
    cache_dir: "${oc.env:CACHE_DIR,/cloud/cloud-ssd1/cached}"
    cache_in_memory: false
    use_mmap: false
    usage_ratio: 1.0

trainer:
  log_step: 10
  n_epochs: 300
  eval_partitions: ["val"]
  ddp:
    enabled: auto
    backend: nccl
    find_unused_parameters: false
    distributed_eval: true
  dynamic_eval:
    enabled: true
  lr_scheduler_step_per: epoch
  warmup:
    enabled: true
    epochs: 30
    start_factor: 0.1
    end_factor: 1.0
  amp: true
  amp_dtype: bf16
  et_threshold_search:
    enabled: false
    parts: ["val"]
    channel_index: 2
    thresholds: [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]
    apply_sigmoid: true
    smooth: 1e-5
    log_all: false
  epoch_len: null
  eval_interval: 1
  validation_policy:
    enabled: true
    default_mode: quick
    always_eval_epoch1: true
    phases:
      - max_epoch_ratio: 0.5
        interval: 10
        mode: quick
      - max_epoch_ratio: 0.8
        interval: 5
        mode: quick
      - max_epoch_ratio: 1.0
        interval: 1
        mode: quick
    full_eval:
      enabled: false
      interval: 50
      epochs: []
    quick:
      max_batches: 32
      roi_size: ${trainer.sw_roi_size}
      random_crop: true
      pad_if_needed: true
      use_sliding_window: false
    post_training_full_eval:
      enabled: true
      save_candidates: true
      top_k: 5
      metric: "val_MeanDice"
      mode: max
      source_modes: ["quick"]
      partitions: ["val"]
      save_summary_path: "post_full_eval_summary.json"
  use_sliding_window_inference: true
  sw_roi_size: [96, 96, 96]
  sw_batch_size: 4
  sw_overlap: 0.5
  device_tensors: ["image", "label"]
  resume_from: null
  device: auto
  override: true
  monitor: "max val_MeanDice"
  save_period: 10
  early_stop: ${trainer.n_epochs}
  save_dir: "saved"
  seed: 42
